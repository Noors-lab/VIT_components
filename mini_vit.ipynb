{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Noors-lab/VIT_components/blob/main/mini_vit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "899b8ff3",
      "metadata": {
        "id": "899b8ff3"
      },
      "source": [
        "# the libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n"
      ],
      "metadata": {
        "id": "Q-GtBjORJ_3E"
      },
      "id": "Q-GtBjORJ_3E",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "VitInput\n"
      ],
      "metadata": {
        "id": "ISwnr1C_KHiB"
      },
      "id": "ISwnr1C_KHiB"
    },
    {
      "cell_type": "code",
      "source": [
        "class VitInput(nn.Module):\n",
        "  def __init__(self,img_size=32,patch_size=4,in_channels=3,embed_dim=128):\n",
        "    super().__init__()\n",
        "\n",
        "    #patch_embedding\n",
        "\n",
        "    self.patch_embed=nn.Conv2d(\n",
        "        in_channels=in_channels,\n",
        "        stride=patch_size,\n",
        "        kernel_size=patch_size,\n",
        "        out_channels=embed_dim\n",
        "\n",
        "    )\n",
        "  #number of patches\n",
        "    num_patches = (img_size//patch_size)**2\n",
        "\n",
        "  #CLS token\n",
        "    self.cls_token = nn.Parameter(torch.randn(1,1,embed_dim))\n",
        "\n",
        "  #positional encoding\n",
        "    self.pos_embed = nn.Parameter(torch.randn(1,num_patches+1,embed_dim))\n",
        "\n",
        "  def forward(self,x):\n",
        "    B = x.shape[0]\n",
        "    x = self.patch_embed(x)\n",
        "    x = x.flatten(2)\n",
        "    x = x.transpose(1,2)\n",
        "\n",
        "    #expand cls token to batch\n",
        "    cls_tokens = self.cls_token.expand(B,-1,-1)\n",
        "\n",
        "    # concatenating cls token\n",
        "    x = torch.cat((cls_tokens,x),dim=1)\n",
        "\n",
        "    # adding positional embedding\n",
        "    x = x+self.pos_embed\n",
        "    return x\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EUShDsKnKPqO"
      },
      "id": "EUShDsKnKPqO",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "encoder_block"
      ],
      "metadata": {
        "id": "nBoGHBXsN4-v"
      },
      "id": "nBoGHBXsN4-v"
    },
    {
      "cell_type": "code",
      "source": [
        "class encoder_block(nn.Module):\n",
        "  def __init__(self,embed_dim=128,num_heads=4,mlp_ratio=4.0,dropout=0):\n",
        "    super().__init__()\n",
        "    self.norm1 = nn.LayerNorm(embed_dim)\n",
        "    self.attn = nn.MultiheadAttention(embed_dim,\n",
        "                                      num_heads,\n",
        "                                      dropout=dropout,\n",
        "                                      batch_first=True) #IMPORTANT\n",
        "\n",
        "    self.norm2 = nn.LayerNorm(embed_dim)\n",
        "    hidden_dim = int(embed_dim*mlp_ratio)\n",
        "    self.MLP = nn.Sequential(\n",
        "        nn.Linear(embed_dim, hidden_dim),\n",
        "        nn.GELU(),\n",
        "        nn.Linear(hidden_dim, embed_dim)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = x + self.attn(self.norm1(x),\n",
        "                      self.norm1(x),\n",
        "                      self.norm1(x))[0]\n",
        "\n",
        "\n",
        "    #feed forward net\n",
        "    x = x + self.MLP(self.norm2(x))\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "DfSzVoCUNwUV"
      },
      "id": "DfSzVoCUNwUV",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mini_vit"
      ],
      "metadata": {
        "id": "JXgmozq10Njk"
      },
      "id": "JXgmozq10Njk"
    },
    {
      "cell_type": "code",
      "source": [
        "class mini_vit(nn.Module):\n",
        "  def __init__(self,img_size=32,\n",
        "               patch_size=4,\n",
        "               in_channels=3,\n",
        "               embed_dim=128,\n",
        "               depth=4,\n",
        "               num_heads=4,\n",
        "               num_classes=10):\n",
        "    super().__init__()\n",
        "\n",
        "    self.vit_input = VitInput(\n",
        "        img_size=img_size,\n",
        "        patch_size=patch_size,\n",
        "        in_channels=in_channels,\n",
        "        embed_dim=embed_dim\n",
        "    )\n",
        "\n",
        "    self.encoder_blocks = nn.Sequential(*[encoder_block(\n",
        "        embed_dim=embed_dim,\n",
        "        num_heads=num_heads,\n",
        "    )for _ in range(depth)\n",
        "    ]\n",
        "                                        )\n",
        "    self.norm = nn.LayerNorm(embed_dim)\n",
        "    self.head = nn.Linear(embed_dim,num_classes)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.vit_input(x)\n",
        "    x = self.encoder_blocks(x)\n",
        "    cls_token = x[:,0]\n",
        "    cls_token = self.norm(cls_token)\n",
        "    logits = self.head(cls_token)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "FDc_weus0PPG"
      },
      "id": "FDc_weus0PPG",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing"
      ],
      "metadata": {
        "id": "yrguZAxU3F2Y"
      },
      "id": "yrguZAxU3F2Y"
    },
    {
      "cell_type": "code",
      "source": [
        "model = mini_vit()\n",
        "x = torch.randn(2, 3, 32, 32)\n",
        "\n",
        "out = model(x)\n",
        "\n",
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHnXmfTh3FQs",
        "outputId": "f7fa298d-a371-40fd-b235-6a812e0bbbd3"
      },
      "id": "uHnXmfTh3FQs",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 10])\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}